# ============================================================================
# DQN Lego Robot Configuration
# ============================================================================

# Robot connection settings
robot:
  bluetooth_address: "00:1A:7D:DA:71:13"  # Replace with your robot's MAC address
  connection_timeout_ms: 5000
  command_timeout_ms: 1000

# Environment settings
environment:
  max_steps_per_episode: 200
  episode_timeout_seconds: 60
  state_normalization: true

# Reward function parameters
reward:
  forward_success: 1.0
  collision_penalty: -1.0
  backward_penalty: -0.1
  turn_reward: 0.0
  orientation_bonus: 0.5

# Training hyperparameters
training:
  num_episodes: 500
  max_steps_per_episode: 200
  learning_rate: 0.001
  gamma: 0.99
  epsilon_start: 1.0
  epsilon_end: 0.05
  epsilon_decay: 0.995

# Network architecture
network:
  hidden_dim1: 128
  hidden_dim2: 128

# Replay buffer settings
replay:
  capacity: 10000
  batch_size: 64

# Target network update
target:
  update_frequency: 10  # Update target network every N episodes

# Device configuration
device:
  use_cuda: true
  gpu_memory_fraction: 0.5

# Logging and checkpointing
logging:
  log_file: "training.log"
  log_interval: 10  # Log progress every N episodes
  checkpoint_interval: 50  # Save checkpoint every N episodes
  save_best_model: true
  metrics_file: "training_metrics.csv"

# Model paths
paths:
  best_model: "models/dqn_best.pt"
  final_model: "models/dqn_final.pt"
  checkpoint_dir: "models/checkpoints"
